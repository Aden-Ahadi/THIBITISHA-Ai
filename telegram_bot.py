import io
import os
import requests
import logging
from typing import Dict
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from transformers import pipeline, AutoImageProcessor, AutoModelForImageClassification
from PIL import Image
import asyncio

# Set up logging for production
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Get bot token from environment variable
TOKEN = os.getenv('TELEGRAM_TOKEN')

if not TOKEN:
    logger.error("‚ùå TELEGRAM_TOKEN environment variable not found!")
    logger.error("Please set your bot token in the environment variables")
    exit(1)

# Global variables
classifier = None
processor = None
model_name = "unknown"

def load_ai_detection_model():
    """Load AI detection model with fallbacks"""
    global classifier, processor, model_name
    
    models_to_try = [
        "umm-maybe/AI-image-detector",
        "Organika/sdxl-detector", 
        "saltacc/anime-ai-detect"
    ]
    
    for model in models_to_try:
        try:
            logger.info(f"üîÑ Attempting to load model: {model}")
            classifier = pipeline(
                "image-classification",
                model=model,
                device=-1  # Force CPU usage for compatibility
            )
            model_name = model
            logger.info(f"‚úÖ Successfully loaded model: {model}")
            return True
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to load {model}: {str(e)}")
            continue
    
    logger.error("‚ùå Failed to load any AI detection model")
    return False

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Start command handler"""
    welcome_msg = f"""
ü§ñ **Welcome to Thibitisha AI Detection Bot!**

I can analyze images to detect if they were generated by AI or are real photos.

üìã **Commands:**
/start - Show this welcome message
/info - Bot information and capabilities
/status - Check bot and model status

üì∏ **Usage:**
Just send me any image and I'll analyze it!

üß† **Currently using:** {model_name}
üöÄ **Powered by:** Hugging Face Transformers
"""
    
    await update.message.reply_text(welcome_msg, parse_mode='Markdown')
    logger.info(f"START command received from user {update.effective_user.first_name}")

async def info(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Info command handler"""
    info_msg = f"""
‚ÑπÔ∏è **Bot Information**

üéØ **Purpose:** AI-Generated Image Detection
üìä **Model:** {model_name}
üîß **Framework:** Transformers + PyTorch
üíæ **Processing:** CPU-optimized

üìã **Supported Formats:**
‚Ä¢ JPEG/JPG, PNG, WebP
‚Ä¢ GIF (static), BMP, TIFF
‚Ä¢ Max size: 20MB

üé≤ **Detection Categories:**
‚Ä¢ Real photographs
‚Ä¢ AI-generated images
‚Ä¢ Digital artwork
‚Ä¢ Synthetic content

‚ö° **Response Time:** 2-10 seconds per image
üîí **Privacy:** Images are not stored

Made with ‚ù§Ô∏è using Python
"""
    
    await update.message.reply_text(info_msg, parse_mode='Markdown')

async def status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Status command handler"""
    bot_status = "üü¢ Online" if classifier else "üî¥ Model Error"
    
    status_msg = f"""
üìä **Bot Status Report**

ü§ñ **Bot:** üü¢ Online and Ready
üß† **AI Model:** {bot_status}
üì° **Connection:** üü¢ Connected to Telegram
üîß **Model Name:** {model_name}

üíæ **System Info:**
‚Ä¢ Python: 3.11+
‚Ä¢ Framework: Transformers
‚Ä¢ Device: CPU

üïê **Last Update:** Just now
"""
    
    await update.message.reply_text(status_msg, parse_mode='Markdown')

def format_ai_detection_result(prediction: Dict, confidence_threshold: float = 0.7) -> str:
    """Format the AI detection results for user display"""
    
    # Extract probabilities
    results = {item['label']: item['score'] for item in prediction}
    
    # Determine AI probability
    ai_prob = results.get('ai', results.get('AI', results.get('artificial', 0)))
    real_prob = results.get('real', results.get('REAL', results.get('human', 1 - ai_prob)))
    
    # Ensure probabilities are valid
    if ai_prob + real_prob == 0:
        ai_prob = 0.5
        real_prob = 0.5
    
    ai_percentage = ai_prob * 100
    real_percentage = real_prob * 100
    
    # Determine verdict and confidence
    if ai_percentage > 70:
        verdict = "‚ö†Ô∏è Likely AI-Generated"
        emoji = "üî¥"
        confidence = "High" if ai_percentage > 85 else "Medium"
    elif ai_percentage < 30:
        verdict = "‚úÖ Very Likely Real Photo"
        emoji = "üü¢"
        confidence = "High" if ai_percentage < 15 else "Medium"
    else:
        verdict = "ü§î Uncertain - Could be Either"
        emoji = "üü°"
        confidence = "Low"
    
    result_msg = f"""{emoji} **AI Detection Results**

**Verdict:** {verdict}
**AI Probability:** {ai_percentage:.1f}%
**Confidence:** {confidence}

üìä **Breakdown:**
‚Ä¢ Real Photo: {real_percentage:.1f}%
‚Ä¢ AI-Generated: {ai_percentage:.1f}%

üîß **Model:** {model_name.split('/')[-1]}
üöÄ **Powered by** Hugging Face
"""
    
    return result_msg

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle photo uploads and perform AI detection"""
    
    if not classifier:
        await update.message.reply_text(
            "‚ùå **Model Error**\n\nAI detection model is not loaded. Please try again later or contact support.",
            parse_mode='Markdown'
        )
        return
    
    try:
        # Send initial processing message
        processing_msg = await update.message.reply_text("üì• **Downloading image...**", parse_mode='Markdown')
        
        # Get the largest photo size
        photo = update.message.photo[-1]
        
        # Download the photo
        file = await context.bot.get_file(photo.file_id)
        image_data = await file.download_as_bytearray()
        
        # Update status
        await processing_msg.edit_text("üß† **Running AI detection...**", parse_mode='Markdown')
        
        # Load image with PIL
        image = Image.open(io.BytesIO(image_data))
        
        # Convert to RGB if necessary
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Resize if too large (to prevent memory issues)
        if max(image.size) > 1024:
            image.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
        
        # Run AI detection
        prediction = classifier(image)
        
        # Format and send results
        result_msg = format_ai_detection_result(prediction)
        
        await processing_msg.edit_text(result_msg, parse_mode='Markdown')
        
        logger.info(f"Image processed successfully for user {update.effective_user.first_name}")
        
    except Exception as e:
        error_msg = f"""
‚ùå **Processing Error**

Sorry, I couldn't analyze this image. This might be due to:
‚Ä¢ Unsupported image format
‚Ä¢ Network connection issues  
‚Ä¢ Temporary server overload

Please try again with a different image or wait a moment.

**Error details:** {str(e)[:100]}...
"""
        
        await processing_msg.edit_text(error_msg, parse_mode='Markdown')
        logger.error(f"Error processing image: {str(e)}")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle text messages"""
    response = """
üì∏ **Send me an image to analyze!**

I can detect if images are:
‚Ä¢ Real photographs
‚Ä¢ AI-generated content
‚Ä¢ Digital artwork

Just upload any image and I'll analyze it for you!

Use /info for more details about my capabilities.
"""
    
    await update.message.reply_text(response, parse_mode='Markdown')

def main():
    """Main function to run the bot"""
    
    # Load AI detection model
    if not load_ai_detection_model():
        logger.error("Failed to load AI detection model. Exiting.")
        return
    
    logger.info("üöÄ Starting Thibitisha AI Detection Bot...")
    
    # Create application
    application = ApplicationBuilder().token(TOKEN).build()
    
    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("info", info))
    application.add_handler(CommandHandler("status", status))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    logger.info("‚úÖ Bot handlers registered!")
    
    # Start the bot
    logger.info("üéØ Bot is now running! Press Ctrl+C to stop")
    application.run_polling(drop_pending_updates=True)

if __name__ == '__main__':
    main()